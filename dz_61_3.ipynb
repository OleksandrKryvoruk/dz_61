{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b625ab",
   "metadata": {},
   "source": [
    "## 3. Реалізуйте алгоритм Хаффмана для стиснення текстових даних. Напишіть код для стиснення та розпакування текстового файлу за допомогою цього алгоритму.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00aec818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bitstring import BitArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fd3d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node of a Huffman Tree  \n",
    "class Nodes:  \n",
    "    def __init__(self, probability, symbol, left = None, right = None):  \n",
    "        # probability of the symbol  \n",
    "        self.probability = probability  \n",
    "  \n",
    "        # the symbol  \n",
    "        self.symbol = symbol  \n",
    "  \n",
    "        # the left node  \n",
    "        self.left = left  \n",
    "  \n",
    "        # the right node  \n",
    "        self.right = right  \n",
    "  \n",
    "        # the tree direction (0 or 1)  \n",
    "        self.code = ''  \n",
    "        \n",
    "\"\"\" A supporting function in order to calculate the probabilities of symbols in specified data \"\"\"  \n",
    "def CalculateProbability(the_data):  \n",
    "    the_symbols = dict()  \n",
    "    for item in the_data:  \n",
    "        if the_symbols.get(item) == None:  \n",
    "            the_symbols[item] = 1  \n",
    "        else:   \n",
    "            the_symbols[item] += 1       \n",
    "    return the_symbols  \n",
    "  \n",
    "\"\"\" A supporting function in order to print the codes of symbols by travelling a Huffman Tree \"\"\"  \n",
    "the_codes = dict()  \n",
    "  \n",
    "def CalculateCodes(node, value = ''):  \n",
    "    # a huffman code for current node  \n",
    "    newValue = value + str(node.code)  \n",
    "  \n",
    "    if(node.left):  \n",
    "        CalculateCodes(node.left, newValue)  \n",
    "    if(node.right):  \n",
    "        CalculateCodes(node.right, newValue)  \n",
    "  \n",
    "    if(not node.left and not node.right):  \n",
    "        the_codes[node.symbol] = newValue  \n",
    "           \n",
    "    return the_codes  \n",
    "  \n",
    "\"\"\" A supporting function in order to get the encoded result \"\"\"  \n",
    "def OutputEncoded(the_data, coding):  \n",
    "    encodingOutput = []  \n",
    "    for element in the_data:  \n",
    "        # print(coding[element], end = '')  \n",
    "        encodingOutput.append(coding[element])  \n",
    "          \n",
    "    the_string = ''.join([str(item) for item in encodingOutput])      \n",
    "    return the_string  \n",
    "          \n",
    "\"\"\" A supporting function in order to calculate the space difference between compressed and non compressed data\"\"\"      \n",
    "def TotalGain(the_data, coding):  \n",
    "    # total bit space to store the data before compression  \n",
    "    beforeCompression = len(the_data) * 8  \n",
    "    afterCompression = 0  \n",
    "    the_symbols = coding.keys()  \n",
    "    for symbol in the_symbols:  \n",
    "        the_count = the_data.count(symbol)  \n",
    "        # calculating how many bit is required for that symbol in total  \n",
    "        afterCompression += the_count * len(coding[symbol])  \n",
    "#     print(\"Space usage before compression (in bits):\", beforeCompression)  \n",
    "#     print(\"Space usage after compression (in bits):\",  afterCompression)  \n",
    "\n",
    "def HuffmanEncoding(the_data):  \n",
    "    symbolWithProbs = CalculateProbability(the_data)  \n",
    "    the_symbols = symbolWithProbs.keys()  \n",
    "    the_probabilities = symbolWithProbs.values()  \n",
    "    print(\"symbols: \", the_symbols)  \n",
    "    print(\"probabilities: \", the_probabilities)  \n",
    "      \n",
    "    the_nodes = []  \n",
    "      \n",
    "    # converting symbols and probabilities into huffman tree nodes  \n",
    "    for symbol in the_symbols:  \n",
    "        the_nodes.append(Nodes(symbolWithProbs.get(symbol), symbol))  \n",
    "      \n",
    "    while len(the_nodes) > 1:  \n",
    "        # sorting all the nodes in ascending order based on their probability  \n",
    "        the_nodes = sorted(the_nodes, key = lambda x: x.probability)  \n",
    "        # for node in nodes:    \n",
    "        #      print(node.symbol, node.prob)  \n",
    "      \n",
    "        # picking two smallest nodes  \n",
    "        right = the_nodes[0]  \n",
    "        left = the_nodes[1]  \n",
    "      \n",
    "        left.code = 0  \n",
    "        right.code = 1  \n",
    "      \n",
    "        # combining the 2 smallest nodes to create new node  \n",
    "        newNode = Nodes(left.probability + right.probability, left.symbol + right.symbol, left, right)  \n",
    "      \n",
    "        the_nodes.remove(left)  \n",
    "        the_nodes.remove(right)  \n",
    "        the_nodes.append(newNode)  \n",
    "              \n",
    "    huffmanEncoding = CalculateCodes(the_nodes[0])  \n",
    "    print(\"symbols with codes\", huffmanEncoding)  \n",
    "    TotalGain(the_data, huffmanEncoding)  \n",
    "    encodedOutput = OutputEncoded(the_data,huffmanEncoding)  \n",
    "    return encodedOutput, the_nodes[0]  \n",
    "   \n",
    "def HuffmanDecoding(encodedData, huffmanTree):  \n",
    "    treeHead = huffmanTree  \n",
    "    decodedOutput = []  \n",
    "    for x in encodedData:  \n",
    "        if x == '1':  \n",
    "            huffmanTree = huffmanTree.right     \n",
    "        elif x == '0':  \n",
    "            huffmanTree = huffmanTree.left  \n",
    "        try:  \n",
    "            if huffmanTree.left.symbol == None and huffmanTree.right.symbol == None:  \n",
    "                pass  \n",
    "        except AttributeError:  \n",
    "            decodedOutput.append(huffmanTree.symbol)  \n",
    "            huffmanTree = treeHead  \n",
    "          \n",
    "    string = ''.join([str(item) for item in decodedOutput])  \n",
    "    return string  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0560dea",
   "metadata": {},
   "source": [
    "### Reading text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69fb6fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "\n",
      " Image Feature Extraction – це процес отримання важливих ознак зображення з метою його подальшого аналізу та розпізнавання об'єктів на ньому. Він включає використання математичних методів та алгоритмів, що дозволяють зменшити обсяг даних та виокремити значущі ознаки.\n",
      "Одним з основних методів Feature Extraction є використання фільтрів, які дозволяють виокремлювати конкретні деталі зображення, наприклад, контури, границі та текстури.\n",
      "Іншим методом є використання алгоритмів класифікації, таких як Principal Component Analysis (PCA) та Independent Component Analysis (ICA), які дозволяють зменшити розмірність даних та виокремити найважливіші ознаки зображення.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = 'text.txt'\n",
    "with open(filename, 'r', encoding='utf8') as file:\n",
    "    text = file.read() \n",
    "print('Original text:\\n\\n', text)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4464698",
   "metadata": {},
   "source": [
    "### Creating HuffmanTree & encoding text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bf1206a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbols:  dict_keys(['I', 'm', 'a', 'g', 'e', ' ', 'F', 't', 'u', 'r', 'E', 'x', 'c', 'i', 'o', 'n', '–', 'ц', 'е', 'п', 'р', 'о', 'с', 'т', 'и', 'м', 'а', 'н', 'я', 'в', 'ж', 'л', 'х', 'з', 'к', 'б', 'ю', 'й', 'г', 'д', 'ь', 'ш', 'і', 'у', \"'\", 'є', '.', 'В', 'ч', ',', 'щ', '\\n', 'О', 'ф', 'І', 'ї', 'P', 'p', 'l', 'C', 'A', 'y', 's', '(', ')', 'd'])\n",
      "probabilities:  dict_values([3, 3, 8, 1, 10, 80, 2, 9, 2, 5, 2, 2, 3, 6, 6, 12, 1, 4, 18, 4, 22, 42, 9, 35, 39, 19, 41, 41, 15, 23, 5, 15, 6, 18, 22, 5, 6, 2, 6, 12, 7, 5, 22, 5, 1, 4, 4, 1, 3, 7, 2, 3, 1, 2, 1, 1, 2, 4, 3, 4, 4, 2, 4, 2, 2, 2])\n",
      "symbols with codes {'є': '00000000', 'п': '00000001', 'a': '0000001', 'л': '000001', 'я': '000010', 'ц': '00001100', 'F': '000011010', 'ї': '000011011', ',': '0000111', 'ь': '0001000', 'l': '00010010', '\\n': '00010011', 'ч': '00010100', 'c': '00010101', 'm': '00010110', 'I': '00010111', 'г': '0001100', 'ю': '0001101', 'х': '0001110', 'o': '0001111', 'д': '001000', 'n': '001001', 'в': '00101', 'і': '00110', 'к': '00111', 'р': '01000', 'i': '0100100', 'у': '0100101', 'ш': '0100110', 'б': '0100111', 'о': '0101', 'н': '0110', 'а': '0111', ' ': '100', 'ж': '1010000', 'r': '1010001', 'e': '101001', 'м': '10101', 'и': '1011', 'с': '110000', 't': '110001', 'з': '11001', 'т': '1101', 'е': '11100', 'І': '111010000', 'О': '111010001', 'В': '111010010', \"'\": '111010011', '–': '111010100', 'g': '111010101', 'd': '11101011', ')': '11101100', '(': '11101101', 'y': '11101110', 'P': '11101111', 'ф': '11110000', 'щ': '11110001', 'й': '11110010', 'x': '11110011', 'E': '11110100', 'u': '11110101', 's': '1111011', 'A': '1111100', 'C': '1111101', 'p': '1111110', '.': '1111111'}\n"
     ]
    }
   ],
   "source": [
    "encoding, tree = HuffmanEncoding(text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7133543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output:  000101110001011000000011110101011010011000000110101010010000001110001111101011010001101001100111101001111001111000110100010000001000101011100010100100000111100100110011101010010000001100111001000000000101000010100001100111001100001000101110101000101110101011101100110000010100001010111101000000000110110010110110001110100010111001011001110011110011001010101001110100001111010000111000110011000001010011001100101011110011010101000110110011110010010100011000101100000000010101001000011100000100010000100110010100011000101100011101100111000001001101100101001011001101011110001000010111001000000010011011001011001110010101110110011000001010001010100111111010011000000000011111010011000101100011001111000110000100001011010101001011111111100111010010001100110100001010011100000100011010001010001110000000010000101101100111010101000101111000011010111011001100000101001010101111101111001010101111101101100010100011010110001110100101011110011010101001000001100010110011010111100011100000100011000101010001011110110101001100010100001111001111000101011000010000101110010010101010000010000100001101110100010001001100110101111000110010011010111101101110001010100111110000000010000110010000100001110110101100011101001101011110000101101101010011101000111001010110111101101110011001011001110001010001001011111000100110100010111001011001110011110111111111000100111110100010010000110101110101100110011000101110000011001010010101101011000111010010101111001101010100100000110001011000000110101010010000001110001111101011010001101001100111101001111001111000110100010000001000101011100010100100000111100100110000000000100001011011001110101010001011110000110101110110011000001010011110000001100000010001000110101000001100010100001111000000100011100110100001000010111001001010101000001000010000110111010001000100001011011010100111010001110010101000001000110100101011111011011100001110101011000111010001110011010110001101000010001110011010111000001001101001100101010100111010000111101000011100011001100000100000111100011001110000000101000101100111000001011100100000001111000011101010110110101001010100010110000111100000110001000011101101011000011000011010011010111100110111100001111100001101010010101000101111111110001001111101000001100100110101110101100101011110011010101001000010110101100000000001000010110110011101010100010111100001101011101100110000010100011100000100011000101010001011110110101001100010110000111000001011111000010111111000000110001110111000011000011000001101100001111001101011100111101100011101000000100011110011101111101000101001000010010001010101001001111110000000100010010100111110100011110001011011111100001111001001101001001001110001100111110000100100000010001001011101110111101101001001111011100111011011110111111111011111100111011001001101011110000010111001001111010111010011111110101001001001111010111010010010011100011001111101000111100010110111111000011110010011010010010011100011001111100001001000000100010010111011101111011010010011110111001110110100010111111110111111001110110000001111000000100011100110100001000010111001001010101000001000010000110111010001000100110011010111100011001001101011110110111000100001011100110101001100100001100011011000011010001000100001000011101101011000111010011010111100001011011010100111010001110010101101111011011100011001111111001000101011110100000000011011001010011001001100011010001011100101100111001111011100110010101010011101000011110100001110001100110000010111111100010011\n"
     ]
    }
   ],
   "source": [
    "print('Encoded output: ', encoding)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b65bee",
   "metadata": {},
   "source": [
    "### Converting code to bytes & writing compressed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cabc9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(encoding, 2)\n",
    "b = n.to_bytes((n.bit_length() + 7) // 8, 'big')\n",
    "\n",
    "with open('text.cmpr', 'wb') as opened_file:\n",
    "        opened_file.write(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d538291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original file size: 1130\n",
      "Compressed file size: 428\n"
     ]
    }
   ],
   "source": [
    "print(f'Original file size: {os.path.getsize(\"text.txt\")}')\n",
    "print(f'Compressed file size: {os.path.getsize(\"text.cmpr\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf83958",
   "metadata": {},
   "source": [
    "### Reading compressed file, converting bytes to string, decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "352febd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.cmpr', mode='rb') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48ee1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_ls = list(BitArray(text).bin)\n",
    "while code_ls[0] == '0' and len(encoding) < len(code_ls) :    \n",
    "    code_ls.pop(0)\n",
    "str_code = ''.join(code_ls)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09ef471b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored text:\n",
      "\n",
      " Image Feature Extraction – це процес отримання важливих ознак зображення з метою його подальшого аналізу та розпізнавання об'єктів на ньому. Він включає використання математичних методів та алгоритмів, що дозволяють зменшити обсяг даних та виокремити значущі ознаки.\n",
      "Одним з основних методів Feature Extraction є використання фільтрів, які дозволяють виокремлювати конкретні деталі зображення, наприклад, контури, границі та текстури.\n",
      "Іншим методом є використання алгоритмів класифікації, таких як Principal Component Analysis (PCA) та Independent Component Analysis (ICA), які дозволяють зменшити розмірність даних та виокремити найважливіші ознаки зображення.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Restored text:\\n\\n', HuffmanDecoding(str_code, tree))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
